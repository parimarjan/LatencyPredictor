%YAML 1.2
---

split_kind : "instances" # instances,query,...;
random_split: "random" # random,custom
num_instances : 1
seed : 1

#gpu: 0
traindata_dir : "LatencyCollectorResults/new"
tags: "exp2_single,exp3_single,"
#tags: "exp2_single,"
use_eval_tags : 1
eval_dirs : "LatencyCollectorResults/new"
#eval_tags : "exp1_single,exp3_single"
eval_tags : "exp1_single"

dataset:
  input_train: ''
  input_test: ''
common:
  batch_size: 16
plan_net:
  arch: "gcn"
  hl: 512
  num_conv_layers: 4
  subplan_ests: 0
  dropout : 0.2
sys_net:
  # mlp / transformer
  #arch: "avg"
  #arch: "mlp"
  arch: "transformer"
  pretrained : 1
  use_pretrained_norms: 1
  save_weights: 0
  #pretrained_fn: null
  #pretrained_fn: "models/all_no123_32_fixed.wt"
  #pretrained_fn: "models/all_no123_32_fixed2.wt"
  #pretrained_fn: "models/all_no123_128_fixed.wt"
  #pretrained_fn: "models/all_noimdb_128_fixed.wt"

  pretrained_fn: "models/all_noimdbwk_128_fixed.wt"
  #pretrained_fn: "models/all_noimdbwk2_128_fixed.wt"   # w/o ceb2
  #pretrained_fn: "models/all_noimdbwk_128_rep2_fixed.wt"

  #pretrained_fn: "models/all_noimdb_32_fixed.wt"
  #pretrained_fn: "models/all_noimdb2_128_fixed.wt"

  #pretrained_fn: "models/all_noimdb3_128_fixed.wt"
  #pretrained_fn: "models/all_noimdb3_128_log_fixed.wt"
  #pretrained_fn: "models/all_noimdb2_32_fixed.wt"
  #pretrained_fn: "models/all_noimdb2_128_fixed2.wt"

  hl: 512
  num_layers: 8
  num_heads: 16
  log_prev_secs: 600
  log_skip: 2

factorized_net:
  arch: "mlp" # dot product
  embedding_size: 128
  #arch: "dot"
  #embedding_size: 32
  pretrained: 1
  hl: 256
  num_layers: 2
...
